{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(s):\n",
    "    if s is np.nan:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        num, denom = s.split('/')\n",
    "        return float(num) / float(denom)\n",
    "    \n",
    "def convert_impact(s):\n",
    "    if s is np.nan:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "#ftr = [1, 1/60]\n",
    "def convert_work_time(s):\n",
    "    ftr = [1, 1/60]\n",
    "    try:\n",
    "        return sum([a*b for a,b in zip(ftr, map(int,s.split(':')))])\n",
    "    except:# (ValueError):\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def eval_mean_sum(df):\n",
    "    df = df.copy(deep=False)\n",
    "    means = []\n",
    "    sums = []\n",
    "    for index, row in df.iterrows():\n",
    "        means.append(0)\n",
    "        sums.append(0)\n",
    "        days_count = 0\n",
    "        entries = np.array([])\n",
    "        exits = np.array([])\n",
    "        for _, val in row.iteritems():\n",
    "            if val == '-' or len(val.split(\"\\n\")) != 4:\n",
    "                continue\n",
    "            days_count += 1\n",
    "            entry = convert_work_time(val.split(\"\\n\")[0])\n",
    "            exit = convert_work_time(val.split(\"\\n\")[1])\n",
    "            entries = np.append(entries, entry)\n",
    "            exits = np.append(exits, exit)\n",
    "\n",
    "        if days_count == 0:\n",
    "            means[index] = 0\n",
    "            sums[index] = 0\n",
    "            continue\n",
    "        \n",
    "        if np.isnan(np.nanmean(entries)):\n",
    "            mean_entry = 8.5\n",
    "        else:\n",
    "            mean_entry = np.nanmean(entries)\n",
    "        if np.isnan(np.nanmean(exits)):\n",
    "            mean_exit = 17\n",
    "        else:\n",
    "            mean_exit = np.nanmean(exits)\n",
    "        \n",
    "        means[index] = abs(mean_exit - mean_entry)\n",
    "        sums[index] = means[index] * days_count\n",
    "\n",
    "    df['Ср продолжительность в УрГУПС'] = pd.Series(means)\n",
    "    df['Общая продолжительность в УрГУПС'] = pd.Series(sums)\n",
    "    df = df.drop(columns=df.columns[1:-2])\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_business_trip(s):\n",
    "    if '(ин)' in s:\n",
    "        return 'Иностр'\n",
    "    if 'Москва' in s:\n",
    "        return 'Москва'\n",
    "    return 'Россия'\n",
    "\n",
    "\n",
    "def convert_conferences(s):\n",
    "    if 'ургупс' in s.lower() or 'уральский государственный университет путей сообщения' in s.lower():\n",
    "        return 'в ургупс'\n",
    "    return 'НЕ в ургупс'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные из отдела кадров</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stepan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Stepan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "HR = pd.read_excel('Работники241019 с внутренними.xlsx', sheet_name='Данные')\n",
    "HR = HR.drop(columns=['Общий стаж лет', 'Педагогический стаж лет', 'Отрасль науки'])\n",
    "HR = HR.rename(columns={'Сотрудник': 'ФИО', \n",
    "                        'Физическое лицо.Внешние руководители/специалисты стаж (Физические лица)': 'Дата приема внешнее место работы', \n",
    "                        'Физическое лицо.Внешние руководители/специалисты (Физические лица)': 'Внешнее совместительство'})\n",
    "HR['ФИО'] = HR['ФИО'].str.title()\n",
    "HR['ФИО'] = HR['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "HR['ФИО'] = HR['ФИО'].replace('ё', 'е', regex=True)\n",
    "HR['ФИО'] = HR['ФИО'].str.replace('Осн.', '').str.strip('()').str.strip()\n",
    "\n",
    "external_work = HR[HR['Вид занятости'] == 'Внешнее совместительство'][['ФИО', 'Внешнее совместительство', 'Дата приема внешнее место работы']]\n",
    "external_work['Внешнее совместительство'] = external_work['Внешнее совместительство'].str.lower()\n",
    "searchfor = ['начальник', 'директор', 'руководител', 'главн']\n",
    "external_work['Внешнее совместительство'] = external_work['Внешнее совместительство'].str.contains('|'.join(searchfor))\n",
    "external_work['Внешнее совместительство'] = external_work['Внешнее совместительство'].map({np.nan: 'есть',\n",
    "                                                                                           False: 'есть_специалист',\n",
    "                                                                                           True: 'есть_начальник_директор_руководитель'})\n",
    "HR = HR.drop(columns=['Дата приема внешнее место работы', 'Внешнее совместительство'])\n",
    "\n",
    "HR['Количество ставок'] = HR['Количество ставок'].apply(convert)\n",
    "HR_PPS = HR[(HR['Категория персонала'] == 'ППС')]\n",
    "HR_PPS_NR = HR[(HR['Категория персонала'] == 'ППС') | (HR['Категория персонала'] == 'НР')]\n",
    "cat_HR = HR[(HR['Вид занятости'] == 'Основное место работы') | (HR['Вид занятости'] == 'Внешнее совместительство')][['ФИО', 'Категория персонала']].drop_duplicates()\n",
    "cat_HR = cat_HR[~((cat_HR['ФИО'] == 'Евсеев Александр Владимирович') & (cat_HR['Категория персонала'] == 'ППС'))]\n",
    "HR_NR_ONLY = HR_PPS_NR[~(HR_PPS_NR['ФИО'].isin(HR_PPS_NR[(HR_PPS_NR['Категория персонала'] == 'ППС')]['ФИО']))]\n",
    "HR_NOT_PPS_NR = HR[~((HR['Категория персонала'] == 'ППС') | (HR['Категория персонала'] == 'НР'))]\n",
    "\n",
    "temp_PPS_NR = HR_PPS_NR.groupby(['ФИО']).sum()[['Количество ставок']].reset_index(level=0)\n",
    "temp_NOT_PPS_NR = HR_NOT_PPS_NR.groupby(['ФИО']).sum()[['Количество ставок']].reset_index(level=0)\n",
    "HR_PPS_NR = HR_PPS_NR.drop(['Категория персонала', 'Вид занятости', 'Количество ставок'], axis=1)\n",
    "\n",
    "positions = HR_PPS[['ФИО', 'Должность']]\n",
    "positions['Ранг'] = HR_PPS['Должность'].map({'Ассистент': 0, \n",
    "                                               'Преподаватель': 1, \n",
    "                                               'Старший преподаватель': 1,\n",
    "                                               'Доцент': 2,\n",
    "                                               'Декан факультета': 2,\n",
    "                                               'Профессор': 3})\n",
    "positions = positions.groupby('ФИО', group_keys=False).apply(lambda x: x.loc[x['Ранг'].idxmax()]).reset_index(drop=True).drop(columns=['Ранг'])\n",
    "HR_PPS['Должность'] = HR_PPS['Должность'].map({'Ассистент': 0, \n",
    "                                               'Преподаватель': 1, \n",
    "                                               'Старший преподаватель': 1,\n",
    "                                               'Доцент': 2,\n",
    "                                               'Декан факультета': 2,\n",
    "                                               'Профессор': 3})\n",
    "HR_PPS = HR_PPS.groupby('ФИО', group_keys=False).apply(lambda x: x.loc[x['Должность'].idxmax()]).reset_index(drop=True)\n",
    "HR_PPS = HR_PPS.merge(positions, left_on='ФИО', right_on='ФИО', how='left')\n",
    "HR_PPS['Должность_x'] = HR_PPS['Должность_y']\n",
    "HR_PPS = HR_PPS.drop(columns=['Должность_y']).rename(columns={\"Должность_x\": \"Должность\"})\n",
    "\n",
    "HR_PPS_NR = pd.concat([HR_PPS, HR_NR_ONLY]).reset_index(drop=True).sort_values(by=['ФИО']).drop(columns=['Вид занятости', 'Категория персонала', 'Количество ставок'])\n",
    "\n",
    "HR_PPS_NR = HR_PPS_NR.merge(temp_PPS_NR, left_on='ФИО', right_on='ФИО', how='left')\n",
    "HR_PPS_NR = HR_PPS_NR.merge(temp_NOT_PPS_NR, left_on='ФИО', right_on='ФИО', how='left')\n",
    "HR_PPS_NR = HR_PPS_NR.rename(columns={\"Количество ставок_y\": \"Количество ставок НЕ ППС и НР\", \n",
    "                                      \"Количество ставок_x\": \"Количество ставок ППС и НР\"})\n",
    "HR_PPS_NR = HR_PPS_NR.fillna(value={'Количество ставок ППС и НР': 0,\n",
    "                                    'Количество ставок НЕ ППС и НР': 0})\n",
    "\n",
    "HR_PPS_NR = HR_PPS_NR.merge(cat_HR, left_on='ФИО', right_on='ФИО', how='left').rename(columns={\"Категория персонала\": \"Категория персонала (по осн. или внеш.)\"})\n",
    "\n",
    "HR_PPS_NR = HR_PPS_NR.merge(external_work, left_on='ФИО', right_on='ФИО', how='left').fillna(value={'Внешнее совместительство': 'нет'})\n",
    "\n",
    "HR_PPS_NR_not_ranked = HR_PPS_NR.copy()\n",
    "\n",
    "\n",
    "HR_PPS_NR['Должность'] = HR_PPS_NR['Должность'].map({'Ассистент': 0, \n",
    "                                                     'Преподаватель': 1, \n",
    "                                                     'Старший преподаватель': 1,\n",
    "                                                     'Руководитель центра': 1,\n",
    "                                                     'Заведующий лабораторией химического анализа': 1,\n",
    "                                                     'Доцент': 2,\n",
    "                                                     'Декан факультета': 2,\n",
    "                                                     'Ведущий научный сотрудник': 2,\n",
    "                                                     'Профессор': 3, \n",
    "                                                     'Главный научный сотрудник ': 3})\n",
    "HR_PPS_NR['Ученое звание'] = HR_PPS_NR['Ученое звание'].map({np.nan: 0, \n",
    "                                                             'Доцент': 1, \n",
    "                                                             'Старший научный сотрудник': 1,\n",
    "                                                             'Профессор': 2})\n",
    "HR_PPS_NR['Ученая степень'] = HR_PPS_NR['Ученая степень'].map({np.nan: 0, \n",
    "                                                               'Кандидат наук': 1, \n",
    "                                                               'Доктор наук': 2})\n",
    "HR_PPS_NR['Внешнее совместительство'] = HR_PPS_NR['Внешнее совместительство'].map({'нет': 0, \n",
    "                                                                                   'есть': 1, \n",
    "                                                                                   'есть_специалист': 1, \n",
    "                                                                                   'есть_начальник_директор_руководитель': 2})\n",
    "HR_PPS_NR = HR_PPS_NR.fillna(0)\n",
    "HR_PPS_NR_ranked = HR_PPS_NR.drop(columns=['Подразделение', 'Категория персонала (по осн. или внеш.)']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Добавление стажа работы</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Непрерывный стаж' 'Общий стаж' 'Стаж в УрГУПС' 'Стаж работы в должности'\n",
      " 'Страховой стаж для оплаты больничных листов' 'Педагогический стаж'\n",
      " 'Непрерывный на предприятии'\n",
      " 'Стаж для оплаты больничных листов с учетом нестраховых периодов (с 2010 года)'\n",
      " 'Общий научно-педагогический стаж работы'\n",
      " 'Стаж по территориальным условиям МКС']\n"
     ]
    }
   ],
   "source": [
    "experience = pd.read_excel('Стаж 2019.xls')\n",
    "experience.columns = experience.iloc[5]\n",
    "experience.columns.name = None\n",
    "experience = experience.iloc[6:].reset_index(drop=True)\n",
    "experience = experience.rename(columns={'Сотрудник': 'ФИО'})\n",
    "experience['ФИО'] = experience['ФИО'].str.title()\n",
    "experience['ФИО'] = experience['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "experience['ФИО'] = experience['ФИО'].replace('ё', 'е', regex=True)\n",
    "experience['ФИО'] = experience['ФИО'].str.strip()\n",
    "experience['Вид стажа'] = experience['Вид стажа'].replace('\\s+', ' ', regex=True)\n",
    "experience['Вид стажа'] = experience['Вид стажа'].str.strip()\n",
    "experience = experience[['ФИО', 'Вид стажа', 'Лет', 'Месяцев', 'Дней']]\n",
    "experience['Лет'] = experience['Лет'].str[:].astype('float64').fillna(0)\n",
    "experience['Месяцев'] = experience['Месяцев'].str[:].astype('float64').fillna(0)\n",
    "experience['Дней'] = experience['Дней'].str[:].astype('float64').fillna(0)\n",
    "experience['Лет'] = (experience['Лет'] + ((experience['Месяцев'] + experience['Дней'] / 30) / 12)).round(1)\n",
    "experience = experience.drop(columns=['Месяцев', 'Дней'])\n",
    "print(experience['Вид стажа'].unique())\n",
    "choose_exp = ['Общий стаж', 'Стаж в УрГУПС', 'Стаж работы в должности', 'Педагогический стаж', 'Непрерывный на предприятии']\n",
    "experience = experience[experience['Вид стажа'].isin(choose_exp)]\n",
    "experience = experience.groupby(['Вид стажа', 'ФИО']).sum().unstack(['Вид стажа']).reset_index()\n",
    "experience.columns = experience.columns.get_level_values(1)\n",
    "experience = experience.rename(columns={experience.columns[0]: \"ФИО\"})\n",
    "experience.columns.name = None\n",
    "\n",
    "HR_PPS_NR_not_ranked = HR_PPS_NR_not_ranked.merge(experience, left_on='ФИО', right_on='ФИО', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по НИРС</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIRS = pd.read_excel('Объемы работы ППС по НИРС за 1 и 2 квартал 2019.xlsx', sheet_name='Лист1').fillna(0)\n",
    "NIRS['ФИО'] = NIRS['ФИО'].str.title()\n",
    "NIRS['ФИО'] = NIRS['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "NIRS['ФИО'] = NIRS['ФИО'].replace('ё', 'е', regex=True)\n",
    "NIRS['ФИО'] = NIRS['ФИО'].str.strip()\n",
    "NIRS = NIRS.groupby(['ФИО']).sum().reset_index(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по корпоративной почте</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails = pd.read_excel('Список рассылки Опроса по корпоративной почте.xlsx', sheet_name='Используют КорпПОчту', names=['ФИО'], header=None)\n",
    "mails['ФИО'] = mails['ФИО'].str.title()\n",
    "mails['ФИО'] = mails['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "mails['ФИО'] = mails['ФИО'].replace('ё', 'е', regex=True)\n",
    "mails['ФИО'] = mails['ФИО'].str.strip()\n",
    "mails['Почта'] = pd.Series('есть', index=mails.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по Вовлеченность в НИР (Responses)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_excel('Вовлеченность в НИР (Responses)_управКоммуникация.xlsx', sheet_name='Form Responses 1')\n",
    "responses = responses.rename(columns={\"1.  Укажите, пожалуйста, Ваши Фамилию Имя Отчество (полностью)\": \"ФИО\"})\n",
    "responses['ФИО'] = responses['ФИО'].str.title()\n",
    "responses['ФИО'] = responses['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "responses['ФИО'] = responses['ФИО'].replace('ё', 'е', regex=True)\n",
    "responses['ФИО'] = responses['ФИО'].str.strip()\n",
    "responses = responses.sort_values(by=['ФИО', 'Timestamp'])\n",
    "responses = responses.drop_duplicates(subset=['ФИО'], keep='last')\n",
    "#responses = responses.drop(columns=['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по нагрузке ППС</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "busy_PPS = pd.read_excel('.\\\\Время ППС\\\\Нагрузка ППС 2019-2020 уч.г.xlsx', sheet_name='Лист1')\n",
    "busy_PPS['ФИО'] = busy_PPS['ФИО'].str.title()\n",
    "busy_PPS['ФИО'] = busy_PPS['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "busy_PPS['ФИО'] = busy_PPS['ФИО'].replace('ё', 'е', regex=True)\n",
    "busy_PPS['ФИО'] = busy_PPS['ФИО'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по публикациям</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_excel('Публикации ППС выгрузка окт 2019.xlsx', sheet_name='Данные')\n",
    "articles = articles[articles['Выгрузка'] == 'от 21.10'].drop_duplicates(subset=['ФИО', 'Наименование'])\n",
    "articles = articles.loc[:, ['ФИО', 'Журнал', 'Статусы', 'Год',\n",
    "                            'Зарубежный', 'ИмпактФактор', 'Количество соавторов']]\n",
    "articles['ФИО'] = articles['ФИО'].str.title()\n",
    "articles['ФИО'] = articles['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "articles['ФИО'] = articles['ФИО'].replace('ё', 'е', regex=True)\n",
    "articles['ФИО'] = articles['ФИО'].str.strip()\n",
    "articles = articles.loc[articles['Год'] >= 2015]\n",
    "\n",
    "articles['Журнал'] = articles['Журнал'].str.lower()\n",
    "values = {'Журнал': 'без названия'}\n",
    "articles = articles.fillna(value=values)\n",
    "articles['ИмпактФактор'] = articles['ИмпактФактор'].apply(convert_impact)\n",
    "articles[\"ИмпактФактор\"] = articles.groupby(\"Журнал\")[\"ИмпактФактор\"].transform(lambda x: x.fillna(x.mean()))\n",
    "values = {'ИмпактФактор': 0.}\n",
    "articles = articles.fillna(value=values)\n",
    "\n",
    "articles['Публикация статьи'] = np.where((articles['Журнал']=='транспорт урала') |\n",
    "                                         (articles['Журнал']=='инновационный транспорт') |\n",
    "                                         (articles['Журнал']=='вестник ургупс') |\n",
    "                                         (articles['Журнал']=='инновационный транспорт - 2016: специализация железных дорог'), \n",
    "                                         'ургупс', 'не_ургупс')\n",
    "articles['Статусы'] = articles['Статусы'].map({np.nan:                    np.nan, \n",
    "                                               'РИНЦ':                    'РИНЦ', \n",
    "                                               'ВАК':                     'ВАК',\n",
    "                                               'ВАК, РИНЦ':               'ВАК',\n",
    "                                               'ВАК, РИНЦ, RSCI':         'ВАК',\n",
    "                                               'ВАК, RSCI':               'ВАК',\n",
    "                                               'Scopus':                  'Scopus_or_WoS',\n",
    "                                               'РИНЦ, Scopus, WoS':       'Scopus_or_WoS',\n",
    "                                               'ВАК, РИНЦ, Scopus':       'Scopus_or_WoS', \n",
    "                                               'ВАК, РИНЦ, Scopus, WoS':  'Scopus_or_WoS', \n",
    "                                               'РИНЦ, Scopus':            'Scopus_or_WoS',\n",
    "                                               'РИНЦ, WoS':               'Scopus_or_WoS',\n",
    "                                               'ВАК, RSCI, WoS':          'Scopus_or_WoS',\n",
    "                                               'WoS':                     'Scopus_or_WoS',\n",
    "                                               'ВАК, RSCI, Scopus':       'Scopus_or_WoS',\n",
    "                                               'ВАК, РИНЦ, RSCI, WoS':    'Scopus_or_WoS',\n",
    "                                               'ВАК, РИНЦ, RSCI, Scopus': 'Scopus_or_WoS'})\n",
    "\n",
    "articles = articles.sort_values(by=['Журнал', 'Год'])\n",
    "articles['Статусы'] = articles.groupby(['Журнал'], sort=False)['Статусы'].apply(lambda x: x.bfill())\n",
    "articles = articles.sort_values(by=['ФИО'])\n",
    "values = {'Статусы': 'нет'}\n",
    "articles = articles.fillna(value=values)\n",
    "\n",
    "temp = articles.groupby(['ФИО', 'Статусы', 'Зарубежный', 'Публикация статьи'])['ФИО'].agg('count').to_frame('count').reset_index()\n",
    "temp_status = temp.pivot_table(index=['ФИО'], columns=['Статусы'], values=['count'], aggfunc='sum').fillna(0)\n",
    "temp_foreign = temp.pivot_table(index=['ФИО'], columns=['Зарубежный'], values=['count'], aggfunc='sum').fillna(0)\n",
    "temp_usurt = temp.pivot_table(index=['ФИО'], columns=['Публикация статьи'], values=['count'], aggfunc='sum').fillna(0)\n",
    "\n",
    "temp_status.columns = temp_status.columns.droplevel(0)\n",
    "temp_status.reset_index(inplace=True)\n",
    "temp_foreign.columns = temp_foreign.columns.droplevel(0)\n",
    "temp_foreign.reset_index(inplace=True)\n",
    "temp_usurt.columns = temp_usurt.columns.droplevel(0)\n",
    "temp_usurt.reset_index(inplace=True)\n",
    "temp_foreign = temp_foreign.rename(columns={'Да': 'кол-во Иностранных', \n",
    "                                            'Нет': 'кол-во Отечественных'})\n",
    "temp_status = temp_status.rename(columns={'нет': 'без статуса'})\n",
    "temp_usurt = temp_usurt.rename(columns={'не_ургупс': 'кол-во НЕ в ургупс', \n",
    "                                        'ургупс': 'кол-во в ургупс'})\n",
    "\n",
    "temp = articles[['ФИО', 'ИмпактФактор', 'Количество соавторов']]\n",
    "temp_mean = temp.groupby('ФИО')['ИмпактФактор', 'Количество соавторов'].mean().reset_index()\n",
    "temp_mean = temp_mean.rename(columns={'ИмпактФактор': 'Средний ИмпактФактор', \n",
    "                                      'Количество соавторов': 'Среднее количество соавторов'})\n",
    "temp_min = temp.groupby('ФИО')['Количество соавторов'].min().reset_index()\n",
    "temp_min = temp_min.rename(columns={'Количество соавторов': 'Минимальное количество соавторов'})\n",
    "temp_max = temp.groupby('ФИО')['ИмпактФактор'].max().reset_index()\n",
    "temp_max = temp_max.rename(columns={'ИмпактФактор': 'Максимальный ИмпактФактор'})\n",
    "\n",
    "temp = temp_min.merge(temp_max, left_on='ФИО', right_on='ФИО', how='left')\n",
    "temp = temp_mean.merge(temp, left_on='ФИО', right_on='ФИО', how='left')\n",
    "temp = temp_usurt.merge(temp, left_on='ФИО', right_on='ФИО', how='left')\n",
    "temp = temp_status.merge(temp, left_on='ФИО', right_on='ФИО', how='left')\n",
    "temp = temp_foreign.merge(temp, left_on='ФИО', right_on='ФИО', how='left')\n",
    "\n",
    "articles = temp.drop(columns=['Минимальное количество соавторов']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по времени преподавания</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_teach_time(name):\n",
    "    teach_time = pd.read_excel(name)\n",
    "    teach_time = teach_time.drop(columns=['СотрудникКодКадры', 'Пар', 'учебных часов']).rename(columns={'Сотрудник': 'ФИО', \n",
    "                                                                                                        'Астрономических часов': 'Время преподавания'})\n",
    "    teach_time['ФИО'] = teach_time['ФИО'].str.title()\n",
    "    teach_time['ФИО'] = teach_time['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "    teach_time['ФИО'] = teach_time['ФИО'].replace('ё', 'е', regex=True)\n",
    "    teach_time['ФИО'] = teach_time['ФИО'].str.strip()\n",
    "    return teach_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teach_time_oct = extract_teach_time('.\\\\Время ППС\\\\Сотрудники пары окт2019.xls')\n",
    "teach_time_nov = extract_teach_time('.\\\\Время ППС\\\\Сотрудники пары ноя2019.xls')\n",
    "teach_time_dec = extract_teach_time('.\\\\Время ППС\\\\Сотрудники пары дек2019.xls')\n",
    "teach_time = teach_time_oct.merge(teach_time_nov, on='ФИО', how='outer', suffixes=('_окт2019', '_ноя2019'))\n",
    "teach_time = teach_time.merge(teach_time_dec, on='ФИО', how='outer').rename(columns={'Время преподавания': 'Время преподавания_дек2019'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по времени работы в УрГУПС</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_work_time(name):\n",
    "    work_time = pd.read_excel(name, sheet_name = 'Отработанное время за месяц')\n",
    "    work_time.columns = work_time.iloc[7]\n",
    "    work_time.columns.name = None\n",
    "    work_time = work_time.iloc[8:]\n",
    "    work_time = work_time.iloc[0:-4].dropna(how='all')\n",
    "    work_time = work_time.loc[:, work_time.columns.notnull()].drop(columns=['№'])\n",
    "    work_time['Фамилия, инициалы, должность (специальность, профессия)'] = work_time[\"Фамилия, инициалы, должность (специальность, профессия)\"].str.split(\"\\\\n\", n = 2, expand = True)[0]\n",
    "    work_time = work_time.rename(columns={'Фамилия, инициалы, должность (специальность, профессия)': 'ФИО'})\n",
    "    work_time['ФИО'] = work_time['ФИО'].str.title()\n",
    "    work_time['ФИО'] = work_time['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "    work_time['ФИО'] = work_time['ФИО'].replace('ё', 'е', regex=True)\n",
    "    work_time['ФИО'] = work_time['ФИО'].replace('Белоусов Виталий Витальевич', 'Белоусов Виталий Виталиевич', regex=True)\n",
    "    work_time['ФИО'] = work_time['ФИО'].str.strip()\n",
    "    work_time = work_time.iloc[:,:-1].reset_index(drop=True)\n",
    "    if 'X' in work_time.columns:\n",
    "        work_time = work_time.drop(columns=['X'])\n",
    "    work_time = eval_mean_sum(work_time)\n",
    "    return work_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stepan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: RuntimeWarning: Mean of empty slice\n",
      "C:\\Users\\Stepan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "work_time_oct = extract_work_time('.\\\\Время ППС\\\\Отработанное время за октябрь все работники.xlsx')\n",
    "work_time_nov = extract_work_time('.\\\\Время ППС\\\\Отработанное время за ноябрь все работники.xlsx')\n",
    "work_time_dec = extract_work_time('.\\\\Время ППС\\\\Отработанное время за декабрь все работники.xlsx')\n",
    "work_time = work_time_oct.merge(work_time_nov, on='ФИО', how='outer', suffixes=('_окт2019', '_ноя2019'))\n",
    "work_time = work_time.merge(work_time_dec, on='ФИО', how='outer').rename(columns={'Ср продолжительность в УрГУПС': 'Ср продолжительность в УрГУПС_дек2019',\n",
    "                                                                                  'Общая продолжительность в УрГУПС': 'Общая продолжительность в УрГУПС_дек2019'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Данные по анализу работы в УрГУПС</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_analysis = pd.read_excel('.\\\\Время ППС\\\\общая информация о работе сотрудников (с пропусками)_анализ.xlsx', sheet_name='Sheet1')[['ФИО', 'Расписание, часов', 'Разность Р-П', 'Пребывание, часов', 'Относительное пребывание', 'Среднее в день', 'Классификация ППС по времени работы']]\n",
    "work_analysis['ФИО'] = work_analysis['ФИО'].str.title()\n",
    "work_analysis['ФИО'] = work_analysis['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "work_analysis['ФИО'] = work_analysis['ФИО'].replace('ё', 'е', regex=True)\n",
    "work_analysis['ФИО'] = work_analysis['ФИО'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Командировки и конференции</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_trip = pd.read_excel('Расходы подотчетных лиц.xls')\n",
    "business_trip = business_trip[business_trip['Назначение аванса'] == 'Командировочные расходы'][['Сотрудник', 'Комментарий']].sort_values(by=['Сотрудник']).reset_index(drop=True)\n",
    "business_trip['Комментарий'] = business_trip['Комментарий'].apply(convert_business_trip)\n",
    "business_trip = business_trip.groupby(['Сотрудник', 'Комментарий'])['Сотрудник'].agg('count').to_frame('count').reset_index()\n",
    "business_trip = business_trip.pivot_table(index=['Сотрудник'], columns=['Комментарий'], values=['count'], aggfunc='sum').fillna(0)\n",
    "business_trip.columns = business_trip.columns.droplevel(0)\n",
    "business_trip.reset_index(inplace=True)\n",
    "business_trip = business_trip.rename(columns={'Сотрудник': 'ФИО', \n",
    "                                              'Иностр': 'Кол-во зарубежных командировок', \n",
    "                                              'Москва': 'Кол-во командировок в Москву',\n",
    "                                              'Россия': 'Кол-во командировок в России (кроме Москвы)'})\n",
    "business_trip['ФИО'] = business_trip['ФИО'].str.title()\n",
    "business_trip['ФИО'] = business_trip['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "business_trip['ФИО'] = business_trip['ФИО'].replace('ё', 'е', regex=True)\n",
    "business_trip['ФИО'] = business_trip['ФИО'].str.strip()\n",
    "business_trip.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = pd.read_excel('Конференции 13-11-2019.xlsx')\n",
    "conferences = conferences[['ФИО', 'Наименование', 'МестоПроведения']]\n",
    "conferences = conferences[~(conferences['МестоПроведения'].isnull())]\n",
    "conferences = conferences[['ФИО', 'МестоПроведения']]\n",
    "conferences['МестоПроведения'] = conferences['МестоПроведения'].apply(convert_conferences)\n",
    "conferences = conferences.groupby(['ФИО', 'МестоПроведения'])['ФИО'].agg('count').to_frame('count').reset_index()\n",
    "conferences = conferences.pivot_table(index=['ФИО'], columns=['МестоПроведения'], values=['count'], aggfunc='sum').fillna(0)\n",
    "conferences.columns = conferences.columns.droplevel(0)\n",
    "conferences.reset_index(inplace=True)\n",
    "conferences = conferences.rename(columns={'Сотрудник': 'ФИО', \n",
    "                                          'НЕ в ургупс': 'Кол-во конференций НЕ в УрГУПС', \n",
    "                                          'в ургупс': 'Кол-во конференций в УрГУПС'})\n",
    "conferences['ФИО'] = conferences['ФИО'].str.title()\n",
    "conferences['ФИО'] = conferences['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "conferences['ФИО'] = conferences['ФИО'].replace('ё', 'е', regex=True)\n",
    "conferences['ФИО'] = conferences['ФИО'].str.strip()\n",
    "conferences.columns.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Индекс Хирша</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_h = pd.read_excel('Индекс Хирша всех ППС.xlsx', sheet_name='Sheet1').drop(columns=['№'])\n",
    "index_h['ФИО'] = index_h['ФИО'].str.title()\n",
    "index_h['ФИО'] = index_h['ФИО'].replace('\\s+', ' ', regex=True)\n",
    "index_h['ФИО'] = index_h['ФИО'].replace('ё', 'е', regex=True)\n",
    "index_h['ФИО'] = index_h['ФИО'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Слияние данных</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = HR_PPS_NR_not_ranked.merge(mails, left_on='ФИО', right_on='ФИО', how='left').fillna(value={'Почта': 'нет'})\n",
    "final = final.merge(responses, on='ФИО', how='outer')\n",
    "final = final.merge(busy_PPS, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(NIRS, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(articles, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(business_trip, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(conferences, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(index_h, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(teach_time, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(work_time, left_on='ФИО', right_on='ФИО', how='left')\n",
    "final = final.merge(work_analysis, left_on='ФИО', right_on='ФИО', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final#.set_index('ФИО').to_excel(\"общий массив данных ППС 22.12.19.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final['uuid'] = [uuid.uuid4() for _ in range(len(final.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final[['ФИО', 'uuid']].set_index('ФИО').to_excel(\"сотруник-uuid.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
